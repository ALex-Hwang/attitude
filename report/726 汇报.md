# 7/26 汇报



## 政治态度相关社科论文

没有多少借鉴价值，大部分的研究都是根据分发问卷的形式进行的。



## 十分类器

### 理论

#### Attention

1. Hierarchical Attention Networks for Document Classification

2. Attention-over-Attention Neural Networks for Reading Comprehension

#### Transformer

#### BERT



上述都是似乎是优化传统网络上下文语境的丢失/不匹配的问题。

我觉得在尝试完传统的模型之后可以考虑套用。

---

### 尝试的模型

1. [snownlp](https://github.com/isnowfy/snownlp)

   针对性较差，精度不够。

2. 朴素贝叶斯

   实现简单，精度差强人意。

3. Bi-LSTM

----

### GitHub上可参考的

1. [nlp-tutorial](https://github.com/graykode/nlp-tutorial)
2. [小米9评论情感分析](https://github.com/ALex-Hwang/Sentimental-Analysis)
3. [大众点评](https://github.com/ALex-Hwang/crawler-analysis/tree/master/中文文本情感分析)

---

### 参考博客

1. [文本分类实战五-Bi-LSTM+Attention模型](https://www.cnblogs.com/jiangxinyang/p/10208227.html)
2. [详解BiLSTM及代码实现](https://zhuanlan.zhihu.com/p/47802053)
3. [LSTM原理与实现](https://blog.csdn.net/weixin_44162104/article/details/88660003)

---

### 思路

利用jieba进行分词，转化为词向量，和非文本信息一起扔进模型。



## 无监督学习评估政党态度

K均值聚类吧。

